{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c449924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd1bde",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "Missing values in a dataset refer to the absence of data for one or more attributes. They can arise due to various reasons, such as data entry errors, equipment malfunctions, or non-responses in surveys.\n",
    "\n",
    "It is essential to handle missing values because:\n",
    "\n",
    "Impact on Analysis: Missing values can lead to biased results and inaccurate conclusions.\n",
    "Model Performance: Many machine learning algorithms do not work with missing data, leading to model training failures.\n",
    "Statistical Inference: Missing values can reduce the statistical power of analyses.\n",
    "Some algorithms that are generally not affected by missing values include:\n",
    "\n",
    "Decision Trees (e.g., CART, C4.5)\n",
    "Random Forests\n",
    "K-Nearest Neighbors (KNN) (with imputation)\n",
    "Naive Bayes (with imputation)\n",
    "Q2: List down techniques used to handle missing data. Give an example of each with Python code.\n",
    "Deletion: Remove rows or columns with missing values.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, None], 'B': [4, None, 6]})\n",
    "df_dropped = df.dropna()  # Drops rows with any missing values\n",
    "print(df_dropped)\n",
    "Mean/Median Imputation: Replace missing values with the mean or median of the column.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)  # Mean imputation\n",
    "df['B'].fillna(df['B'].median(), inplace=True)  # Median imputation\n",
    "print(df)\n",
    "Forward/Backward Fill: Use the previous or next value to fill missing data.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "print(df)\n",
    "Interpolation: Estimate missing values based on surrounding data.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "df.interpolate(method='linear', inplace=True)\n",
    "print(df)\n",
    "KNN Imputation: Use K-Nearest Neighbors to estimate missing values.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "print(imputed_data)\n",
    "Q3: Explain imbalanced data. What will happen if imbalanced data is not handled?\n",
    "Imbalanced data occurs when the classes in a dataset are not represented equally. For example, in a binary classification problem, one class may have significantly more instances than the other.\n",
    "\n",
    "If imbalanced data is not handled:\n",
    "\n",
    "Biased Models: The model may become biased towards the majority class, leading to poor performance on the minority class.\n",
    "Misleading Accuracy: High accuracy may be misleading since the model could predict the majority class most of the time, ignoring the minority.\n",
    "Poor Generalization: The model may fail to learn the underlying patterns of the minority class, leading to underperformance in real-world applications.\n",
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
    "Up-sampling: Increases the number of instances in the minority class by replicating existing samples or generating new samples (e.g., SMOTE). This is used when the minority class is underrepresented.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assume df is your DataFrame and the minority class is in the 'target' column\n",
    "minority_class = df[df['target'] == 1]\n",
    "majority_class = df[df['target'] == 0]\n",
    "\n",
    "# Up-sample minority class\n",
    "minority_upsampled = resample(minority_class, \n",
    "                              replace=True,     # Sample with replacement\n",
    "                              n_samples=len(majority_class),    # To match majority class\n",
    "                              random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([majority_class, minority_upsampled])\n",
    "Down-sampling: Reduces the number of instances in the majority class to balance the dataset. This is used when the majority class is overrepresented.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Down-sample majority class\n",
    "majority_downsampled = resample(majority_class, \n",
    "                                 replace=False,    # Sample without replacement\n",
    "                                 n_samples=len(minority_class),    # To match minority class\n",
    "                                 random_state=42)  # Reproducible results\n",
    "\n",
    "# Combine downsampled majority class with minority class\n",
    "df_balanced = pd.concat([majority_downsampled, minority_class])\n",
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "Data Augmentation refers to techniques used to increase the diversity of your training dataset without actually collecting new data. It typically involves generating new examples by applying various transformations to existing data (e.g., rotations, translations, scaling in images).\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a specific data augmentation technique for imbalanced datasets. It creates synthetic examples of the minority class by interpolating between existing minority class instances.\n",
    "\n",
    "Example of using SMOTE:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "Outliers are data points that differ significantly from other observations in the dataset. They can be unusually high or low values.\n",
    "\n",
    "It is essential to handle outliers because:\n",
    "\n",
    "Impact on Statistical Analysis: Outliers can skew mean and variance calculations, affecting the results of statistical analyses.\n",
    "Model Performance: Machine learning models can become biased or less accurate due to outliers.\n",
    "Data Integrity: Identifying and addressing outliers ensures that the data is clean and reliable for decision-making.\n",
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "Deletion: Remove rows or columns with missing values.\n",
    "Imputation: Replace missing values with statistical measures (mean, median) or use advanced methods like KNN imputation.\n",
    "Interpolation: Use surrounding values to estimate missing data.\n",
    "Forward/Backward Fill: Propagate the next or previous values to fill in gaps.\n",
    "Domain-Specific Imputation: Use domain knowledge to inform imputation strategies.\n",
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "Visual Analysis: Use visualizations (e.g., heatmaps) to explore missing data patterns.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(df.isnull(), cbar=False)\n",
    "plt.show()\n",
    "Statistical Tests: Perform tests (e.g., Little's MCAR test) to determine if the missing data is completely at random.\n",
    "\n",
    "Correlation Analysis: Check correlations between missingness in different features to identify patterns.\n",
    "\n",
    "Compare Groups: Analyze the differences between groups with missing and non-missing data to identify systematic differences.\n",
    "\n",
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "Use Appropriate Metrics: Focus on metrics like precision, recall, F1-score, and the area under the ROC curve (AUC-ROC) rather than accuracy.\n",
    "Confusion Matrix: Analyze the confusion matrix to understand model performance on both classes.\n",
    "Cross-Validation: Use stratified cross-validation to ensure both classes are represented in training and validation sets.\n",
    "Ensemble Methods: Utilize ensemble techniques (e.g., Random Forests) that can better handle imbalanced data.\n",
    "Cost-Sensitive Learning: Assign different costs to misclassifications to reflect the importance of correctly identifying the minority class.\n",
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
    "Random Down-sampling: Randomly remove instances from the majority class to balance with the minority class.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "majority_class = df[df['satisfaction'] == 'satisfied']\n",
    "minority_class = df[df['satisfaction'] == 'not satisfied']\n",
    "\n",
    "majority_downsampled = resample(majority_class, \n",
    "                                 replace=False, \n",
    "                                 n_samples=len(minority_class),\n",
    "                                 random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([majority_downsampled, minority_class])\n",
    "Tomek Links: Remove instances of the majority class that are very close to minority class instances.\n",
    "\n",
    "Cluster Centroids: Use clustering techniques to identify centroids of the majority class and use them to create a balanced dataset.\n",
    "\n",
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
    "Random Up-sampling: Replicate instances of the minority class until it matches the majority class.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "minority_upsampled = resample(minority_class,\n",
    "                               replace=True,\n",
    "                               n_samples=len(majority_class),\n",
    "                               random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([majority_class, minority_upsampled])\n",
    "SMOTE: Use SMOTE to generate synthetic instances of the minority class.\n",
    "\n",
    "ADASYN: Similar to SMOTE, but focuses on generating more examples in regions where the minority class is underrepresented.\n",
    "\n",
    "Augmentation Techniques: Apply augmentation techniques relevant to the data type (e.g., adding noise to images) to create new minority instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
